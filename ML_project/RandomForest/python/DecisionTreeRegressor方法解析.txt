DecisionTreeRegressor实现了回归决策树，用于回归问题。它的原型为：
class DecisionTreeRegressor(
                 criterion="mse",
                 splitter="best",
                 max_depth=None,
                 min_samples_split=2,
                 min_samples_leaf=1,
                 min_weight_fraction_leaf=0.,
                 max_features=None,
                 random_state=None,
                 max_leaf_nodes=None,
                 min_impurity_decrease=0.,
                 min_impurity_split=None,
                 presort=False)
参数：
1 criterion:一个字符串，指定切分质量的评价准则。默认为‘mse’，且只支持该字符串，表示均方误差
2 splitter:一个字符串，指定切分原则，可以分为如下。
    2-1‘best’:表示选择最优的切分。
    2-2 ‘random’:表示随机切分。
3 max_features:可以为整数、浮点、字符串或者None，指定寻找best split时考虑的特征数量
    3-1 如果是整数，则每次切分只考虑max_features个特征
    3-2 如果是浮点数，则每次切分只考虑max_features * n_features个特征（max_features指定了百分比）。
    3-3 如果是字符串‘auto’或者‘sqrt’，则max_features等于n_features。
    3-4 如果是字符串‘log2’，则max_features等于log2(n_features).
    3-5 如果是None，则max_feature等于n_features。
    注：如果已经考虑了max_feature个特征，但是还没有找到一个有效的切分，那么还会继续寻找下一个特征，直到找到一个有效的切分为止。
4 max_depth:可以为整数或者None，指定树的最大深度
    4-1 如果为None，则表示树的深度不限（直到每个叶子都是纯的，即叶节点中所有样本点都属于一个类，或者叶子中包含小于min_sampes_split个样本点）
    4-2 如果max_leaf_nodes参数非None，则忽略此选项。
5 min_samples_split:为整数，指定每个内部节点（非叶节点）包含的最少的样本数
6 min_sample_leaf: 为整数，指定每个叶节点包含的最少的样本数
7 min_weight_fraction_leaf:为浮点数，叶节点中样本的最小权重系数。
8 random_state:一个整数或者一个RandomState实例，或者None。
    8-1 如果为整数，则它指定了随机数生成器的种子
    8-2 如果为RandomState实例，则指定了随机数生成器
    8-3 如果为None，则使用默认的随机数生成器
9 presort:一个布尔值，指定是否要提前排序数据从而加速寻找最优切分的过程。设为True时，对于大数据集会减慢总体的训练过程；但是对于一个小数据集
          或者设定了最大深度的情况下，则会加速训练过程。
======================================================
属性有如下5个：
1 feature_importances_:给出了特征的重要程度。该值越高，则该特征越重要（也称为Gini importance）
2 max_features_:max_features的推断值。
3 n_features_:当执行fit之后，特征的数量
4 n_outputs:当执行fit之后，输出的数量。
5 tree_:一个Tree对象，即底层的决策树。
======================================================
方法有以下3种：
1 fit(X, Y[, sample_weight, check_input, ...]):训练模型。
2 predict(X[, check_input]):用模型进行预测，返回模型预测值。
3 score(X, y[, sample_weight]):返回预测性能得分。
   3-1 score不超过1，但是可能为负值（预测效果太差）。
   3-2 score越大，预测性能越好。